{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparar KMeans \"puro\" com KMeans com Improved Density Canopy\n",
    "\n",
    "Métricas erro Quadrático médio\n",
    "\n",
    "Quando bancos de dados UCI usar?\n",
    "\n",
    "1. Calcular MeanDis de cada elemento\n",
    "2. Calcular densidade de cada elemento\n",
    "3. O com maior densidade é o centro e eliminar os que não estão dentro do raio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# X shoudl be a numpy matrix, very likely sparse matrix: http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix\n",
    "# T1 > T2 for overlapping clusters\n",
    "# T1 = Distance to centroid point to not include in other clusters\n",
    "# T2 = Distance to centroid point to include in cluster\n",
    "# T1 > T2 for overlapping clusters\n",
    "# T1 < T2 will have points which reside in no clusters\n",
    "# T1 == T2 will cause all points to reside in mutually exclusive clusters\n",
    "# Distance metric can be any from here: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html\n",
    "# filemap may be a list of point names in their order in X. If included, row numbers from X will be replaced with names from filemap. \n",
    " \n",
    "def canopy(X, T1, T2, distance_metric='euclidean', filemap=None):\n",
    "    canopies = dict()\n",
    "    X1_dist = pairwise_distances(X, metric=distance_metric)\n",
    "    canopy_points = set(range(X.shape[0]))\n",
    "    while canopy_points:\n",
    "        point = canopy_points.pop()\n",
    "        i = len(canopies)\n",
    "        canopies[i] = {\"c\":point, \"points\": list(np.where(X1_dist[point] < T2)[0])}\n",
    "        canopy_points = canopy_points.difference(set(np.where(X1_dist[point] < T1)[0]))\n",
    "    if filemap:\n",
    "        for canopy_id in canopies.keys():\n",
    "            canopy = canopies.pop(canopy_id)\n",
    "            canopy2 = {\"c\":filemap[canopy['c']], \"points\":list()}\n",
    "            for point in canopy['points']:\n",
    "                canopy2[\"points\"].append(filemap[point])\n",
    "            canopies[canopy_id] = canopy2\n",
    "    return canopies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(vector1, vector2):\n",
    "        #print(vector1)\n",
    "        #print(vector2)\n",
    "        return np.sqrt(np.sum(np.power(vector1-vector2, 2)))\n",
    "\n",
    "def getDistance(row_center, row_sample):\n",
    "        #print(row_center)\n",
    "        row_center = np.asarray(row_center)\n",
    "        #row_center = np.asarray(row_sample)\n",
    "        return euclideanDistance(row_center, row_sample)\n",
    "\n",
    "def getSquaredError(data, kmeans):\n",
    "    distances = []\n",
    "    for i in range(k): # Qtd de clusters\n",
    "        distance = 0\n",
    "        for index_labels, value_labels in enumerate(kmeans.labels_): #kmeans.labels_ possui a que cluster cada elemento pertence\n",
    "            if (i == value_labels):\n",
    "                #print(value_labels)\n",
    "                distance = distance + getDistance(kmeans.cluster_centers_[value_labels], data.loc[index_labels].values)\n",
    "        \n",
    "        distances.append(distance) #Erro quadratico medio de cada cluster\n",
    "    \n",
    "    distances = np.asarray(distances)\n",
    "    error = np.sum(distances)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Density Canopy -------------- #\n",
    "\n",
    "def MeanDis(D):\n",
    "    #OBS enumerate com numpy mto mais rápido que iterrows\n",
    "    n = D.shape[0]\n",
    "    D = D.values\n",
    "    meanDis = 0\n",
    "    \n",
    "    for i, row_i in enumerate(D):\n",
    "        for j, row_j in enumerate(D[i+1:,]):\n",
    "            \n",
    "            meanDis = meanDis + euclideanDistance(row_i, row_j)\n",
    "            \n",
    "    meanDis = (2/(n*(n-1))) * meanDis\n",
    "    \n",
    "    return meanDis\n",
    "def getDensitys(D, meanDis): #Definition 2\n",
    "    \n",
    "    densitys = np.zeros(D.shape[0], dtype=int)\n",
    "    \n",
    "    auxD = D.values\n",
    "    \n",
    "    for i, row_i in enumerate(auxD):\n",
    "        aux = 0\n",
    "        for j, row_j in enumerate(auxD):\n",
    "            if euclideanDistance(row_i, row_j) - meanDis < 0:\n",
    "                aux = aux + 1\n",
    "        densitys[i] = aux\n",
    "    df = pd.DataFrame(data= densitys, columns=[\"density\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "def getAs(auxD, new_densitys, meanDis):  #Definition 3 NAO ESTÁ CLARO NO ARTIGO\n",
    "    a = []\n",
    "    densitys = new_densitys.copy().values\n",
    "    for i, row_i in enumerate(auxD.values): # confirmar o valor do somatório\n",
    "        aux = 0\n",
    "        for j, row_j in enumerate(auxD.values ):\n",
    "            if euclideanDistance(row_i, row_j) - meanDis < 0: #Somente dos elementos que pertencem ao cluster\n",
    "                aux = aux + euclideanDistance(row_i, row_j)\n",
    "        if (densitys[i] -1== 0): #So tem 1 elemento\n",
    "            aux = 1\n",
    "        else:\n",
    "            aux = (2/(densitys[i] * (densitys[i] -1))) * aux # calculo de a(i)\n",
    "        #print(densitys[i])\n",
    "        a.append(aux)\n",
    "    return a\n",
    "\n",
    "def getSs(auxD, new_densitys):  #Definition 4\n",
    "    s = []\n",
    "    densitys = new_densitys.values\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i, row_i in enumerate(auxD.values):\n",
    "        maxDist = 0\n",
    "        minDist = float(\"inf\")\n",
    "        dist = 0\n",
    "        flag = 0 #Se flag =0 entao min dist, se flag =1 retornar max dist\n",
    "        \n",
    "        for j, row_j in enumerate(auxD.values):\n",
    "            \n",
    "            dist = euclideanDistance(row_i, row_j)\n",
    "            \n",
    "            if (dist > maxDist):\n",
    "                maxDist = dist\n",
    "            if (dist < minDist):\n",
    "                minDist = dist\n",
    "                \n",
    "                \n",
    "            if densitys[j] == np.amax(densitys): #Se a densidade  for a maxima quer dizer que p(j) == p(i)\n",
    "                flag = 1\n",
    "        \n",
    "        if flag == 1:\n",
    "            s.append(maxDist)\n",
    "        else: # p(j) > p(i)\n",
    "            s.append(minDist)\n",
    "    #print (s)\n",
    "    return s\n",
    "                #print(np.amax(densitys))\n",
    "        \n",
    "def getCenter(D, meanDis,firstExecution = True, index=None): \n",
    "    auxD = D.copy()\n",
    "    \n",
    "    df = getDensitys(D, meanDis)\n",
    "    \n",
    "    if (firstExecution == True): #Primeira execução pega o de maior densidade\n",
    "        rows = D.iloc[df.idxmax(axis = 0)].values \n",
    "        for row in rows:\n",
    "            row_i = row #apenas pra ficar no formato correto\n",
    "            \n",
    "    else :\n",
    "        #print(index)\n",
    "        row_i = D.iloc[index].values #pegando index passado, no caso o com maior peso\n",
    "        \n",
    "    cluster = []\n",
    "    \n",
    "    for j, row_j in enumerate(auxD.values):\n",
    "        if euclideanDistance(row_i, row_j) - meanDis < 0:\n",
    "            cluster.append(j)\n",
    "            \n",
    "    #print (cluster)\n",
    "    \n",
    "    #auxD.drop(cluster, inplace=True)\n",
    "    #display(auxD)\n",
    "    return row_i, cluster # Elemento central e cluster\n",
    "def removeOutliers(auxD, densitys, s, meanDis ):\n",
    "    #remove elemento com densidade = 1 e que o s[i] seja maior que o raio\n",
    "    outliers = []\n",
    "    for i, row_i in enumerate(auxD.values):\n",
    "        if densitys[i] == 1 and s[i] > meanDis:\n",
    "            outliers.append(i)\n",
    "    #print(\"outliers: \", outliers)\n",
    "    \n",
    "    auxD.drop(outliers, inplace=True) #removendo outliers\n",
    "    auxD.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    densitys = np.delete(densitys, outliers, 0)\n",
    "    s = np.delete(s, outliers, 0)\n",
    "    \n",
    "    return auxD, densitys, s\n",
    "\n",
    "def getWeight(D):\n",
    "    \n",
    "    meanDis = MeanDis(D)\n",
    "    centers, cluster = getCenter(D, meanDis)\n",
    "    centers = np.array([centers])\n",
    "    \n",
    "    auxD = D.copy()\n",
    "    \n",
    "    auxD.drop(cluster, inplace=True) #removendo cluster ja identificado\n",
    "    auxD.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    while (not auxD.empty) :\n",
    "\n",
    "        new_densitys = getDensitys(auxD, meanDis)\n",
    "    \n",
    "        a = getAs(auxD, new_densitys, meanDis) #mantem-se meanDis\n",
    "    \n",
    "        s = getSs(auxD, new_densitys)\n",
    "    \n",
    "        densitys = new_densitys.values\n",
    "\n",
    "        auxD, densitys, s = removeOutliers(auxD, densitys, s, meanDis)\n",
    "    \n",
    "        weight = 0\n",
    "        aux_index = None\n",
    "        for i, row_i in enumerate(auxD.values):\n",
    "            if (densitys[i] * (1/a[i]) * s[i]) > weight:\n",
    "                weight = densitys[i] * (1/a[i]) * s[i]\n",
    "                print(\"densidade: \",densitys[i], \"a: \", a[i], \"s: \",s[i], \"weight: \", weight)\n",
    "                aux_index = i\n",
    "        #print(aux_index)\n",
    "        aux_center, cluster = getCenter(auxD, meanDis, firstExecution=False, index= aux_index)\n",
    "    \n",
    "        aux_center = np.array([aux_center])\n",
    "\n",
    "        centers = np.concatenate((centers, aux_center), axis=0)\n",
    "        \n",
    "        auxD.drop(cluster, inplace=True) #removendo cluster ja identificado\n",
    "        auxD.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print(\"KS:\", len(centers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### possiveis problemas que podem estar ocorrendo \n",
    "1. em getAs a função estar errada\n",
    "2. Checar se os valores dropados estão corretos\n",
    "3. Ver se foi retirado o index tb\n",
    "4. Checar se esses limites de outliers são suficientes\n",
    "5. Checar se algum índice não está estranho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"soybean-small\", \"iris\", \"wine\",  \"segmentation\", \"ionosphere\"]\n",
    "ks = [4,3,3,7,2]\n",
    "#kmeansTypes = [\"random\", \"k-means++\"]\n",
    "kmeansTypes = [\"random\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- random test ---------\n",
      "\n",
      "----- soybean-small -----\n",
      "\n",
      "(47, 36)\n",
      "densidade:  [4] a:  [1.42544879] s:  6.928203230275509 weight:  [19.44146505]\n",
      "densidade:  [4] a:  [1.25233081] s:  7.0 weight:  [22.35830967]\n",
      "densidade:  [10] a:  [0.68063463] s:  6.855654600401044 weight:  [100.72444602]\n",
      "densidade:  [10] a:  [0.51850195] s:  6.324555320336759 weight:  [121.97746411]\n",
      "densidade:  [4] a:  [1.42544879] s:  3.3166247903554 weight:  [9.30689283]\n",
      "KS: 3\n",
      "\n",
      "----- iris -----\n",
      "\n",
      "(150, 5)\n",
      "densidade:  [24] a:  [0.05370115] s:  6.498461356351979 weight:  [2904.27787241]\n",
      "densidade:  [24] a:  [0.04989528] s:  6.717886572427373 weight:  [3231.35335588]\n",
      "densidade:  [16] a:  [0.1564202] s:  1.8165902124584954 weight:  [185.81643419]\n",
      "densidade:  [16] a:  [0.09518695] s:  1.284523257866513 weight:  [215.91585604]\n",
      "densidade:  [16] a:  [0.10844554] s:  1.5165750888103098 weight:  [223.75471445]\n",
      "densidade:  [16] a:  [0.11142851] s:  1.562049935181331 weight:  [224.29448082]\n",
      "KS: 3\n",
      "\n",
      "----- wine -----\n",
      "\n",
      "(178, 14)\n",
      "densidade:  [16] a:  [1.07668714] s:  57.77427974453685 weight:  [858.54881936]\n",
      "densidade:  [16] a:  [1.02449849] s:  56.7273875654432 weight:  [885.93415431]\n",
      "densidade:  [11] a:  [0.94543618] s:  84.06465666378469 weight:  [978.07894336]\n",
      "densidade:  [11] a:  [0.86959079] s:  82.05024801912546 weight:  [1037.9051092]\n",
      "densidade:  [11] a:  [0.84244005] s:  82.02780748014663 weight:  [1071.06242235]\n",
      "densidade:  [16] a:  [1.07668714] s:  35.40286005395609 weight:  [526.10060802]\n",
      "densidade:  [16] a:  [0.9816747] s:  41.20869689762102 weight:  [671.64729087]\n",
      "densidade:  [2] a:  [11.33723511] s:  18.034084395943147 weight:  [3.18139021]\n",
      "densidade:  [2] a:  1 s:  25.584637968906264 weight:  [51.16927594]\n",
      "KS: 4\n",
      "\n",
      "----- segmentation -----\n",
      "\n",
      "(210, 20)\n",
      "densidade:  [17] a:  [7.85034285] s:  1508.9448641246222 weight:  [3267.63597107]\n",
      "densidade:  [17] a:  [7.32652713] s:  1507.900734034794 weight:  [3498.83540046]\n",
      "densidade:  [9] a:  1 s:  1402.9880585339356 weight:  [12626.89252681]\n",
      "densidade:  [10] a:  1 s:  1503.8613921595577 weight:  [15038.6139216]\n",
      "densidade:  [16] a:  [7.73009944] s:  362.16178335031 weight:  [749.61371143]\n",
      "densidade:  [16] a:  [7.26545907] s:  363.6184790434578 weight:  [800.76091705]\n",
      "densidade:  [3] a:  [14.0670883] s:  24.54237876366202 weight:  [5.23399972]\n",
      "densidade:  [3] a:  [13.65538303] s:  24.54237876366202 weight:  [5.39180308]\n",
      "KS: 4\n",
      "\n",
      "----- ionosphere -----\n",
      "\n",
      "(351, 35)\n",
      "densidade:  [3] a:  1 s:  8.560014291600218 weight:  [25.68004287]\n",
      "densidade:  [4] a:  1 s:  8.168772334310708 weight:  [32.67508934]\n",
      "densidade:  [5] a:  1 s:  8.090261743157635 weight:  [40.45130872]\n",
      "densidade:  [5] a:  1 s:  8.452027729403163 weight:  [42.26013865]\n",
      "densidade:  [7] a:  1 s:  7.84463029438609 weight:  [54.91241206]\n",
      "densidade:  [3] a:  [2.6056198] s:  7.771796025758782 weight:  [8.94811594]\n",
      "densidade:  [4] a:  [1.30680857] s:  6.852954709773004 weight:  [20.97615483]\n",
      "densidade:  [5] a:  [1.45322671] s:  7.111997196667051 weight:  [24.46967541]\n",
      "densidade:  [5] a:  1 s:  6.738560527449464 weight:  [33.69280264]\n",
      "densidade:  [3] a:  [2.6056198] s:  7.771796025758782 weight:  [8.94811594]\n",
      "densidade:  [2] a:  1 s:  7.073006377524341 weight:  [14.14601276]\n",
      "densidade:  [3] a:  [2.6056198] s:  7.771796025758782 weight:  [8.94811594]\n",
      "densidade:  [2] a:  [3.89822967] s:  3.898229666643565 weight:  [2.]\n",
      "KS: 6\n"
     ]
    }
   ],
   "source": [
    "for kmeansType in kmeansTypes:\n",
    "    print (\"--------- \"+ kmeansType +\" test ---------\")\n",
    "    \n",
    "    for index, file in enumerate(files):\n",
    "        print (\"\\n----- \"+file+\" -----\\n\")\n",
    "        data = pd.read_csv(\"datasets/\"+file+\".data\", header=None)\n",
    "        print (data.shape)\n",
    "\n",
    "        #display(data.head())\n",
    "        if file == \"segmentation\": #Target eh na primeira coluna\n",
    "            target = data.iloc[:,0]\n",
    "            data = data.iloc[:,1:]\n",
    "            \n",
    "            \n",
    "        else: #Target na última coluna\n",
    "            target = data.iloc[:,-1]\n",
    "            data = data.iloc[:,:-1]\n",
    "        \n",
    "        \n",
    "        getWeight(data)\n",
    "        \n",
    "        clustering_times = []\n",
    "        start = time()\n",
    "        k = ks[index]\n",
    "        kmeans = KMeans(n_clusters=k, random_state=100, init=kmeansType, n_init=1, max_iter=100).fit(data)\n",
    "        #display(data)\n",
    "        error = getSquaredError(data, kmeans)\n",
    "        \n",
    "        \n",
    "                #print(kmeans.labels_)\n",
    "        end = time()\n",
    "        T1 = error/(data.shape[0])\n",
    "        T2 = error/(data.shape[0]/2)\n",
    "        \n",
    "        #print(canopy(data.values, T1, T2))\n",
    "        #print(\"Erro quadrático médio: \",error)\n",
    "        clustering_times.append(end - start)\n",
    "        #print(clustering_times)\n",
    "        #print(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usando numpy em vez do pandas pode tornar mais rápido pra essas operações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
