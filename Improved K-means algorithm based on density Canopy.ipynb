{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparar KMeans com Improved Density Canopy com KMeans \"puro\" e outras variações.\n",
    "\n",
    "Métricas erro Quadrático médio\n",
    "\n",
    "1. Calcular MeanDis de cada elemento\n",
    "2. Calcular densidade de cada elemento\n",
    "3. O com maior densidade é o centro e eliminar os que não estão dentro do raio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X shoudl be a numpy matrix, very likely sparse matrix: http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix\n",
    "# T1 > T2 for overlapping clusters\n",
    "# T1 = Distance to centroid point to not include in other clusters\n",
    "# T2 = Distance to centroid point to include in cluster\n",
    "# T1 > T2 for overlapping clusters\n",
    "# T1 < T2 will have points which reside in no clusters\n",
    "# T1 == T2 will cause all points to reside in mutually exclusive clusters\n",
    "# Distance metric can be any from here: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html\n",
    "# filemap may be a list of point names in their order in X. If included, row numbers from X will be replaced with names from filemap. \n",
    " \n",
    "def canopy(X, T1, T2, distance_metric='euclidean', filemap=None):\n",
    "    canopies = dict()\n",
    "    X1_dist = pairwise_distances(X, metric=distance_metric)\n",
    "    canopy_points = set(range(X.shape[0]))\n",
    "    while canopy_points:\n",
    "        point = canopy_points.pop()\n",
    "        i = len(canopies)\n",
    "        canopies[i] = {\"c\":point, \"points\": list(np.where(X1_dist[point] < T2)[0])}\n",
    "        canopy_points = canopy_points.difference(set(np.where(X1_dist[point] < T1)[0]))\n",
    "    if filemap:\n",
    "        for canopy_id in canopies.keys():\n",
    "            canopy = canopies.pop(canopy_id)\n",
    "            canopy2 = {\"c\":filemap[canopy['c']], \"points\":list()}\n",
    "            for point in canopy['points']:\n",
    "                canopy2[\"points\"].append(filemap[point])\n",
    "            canopies[canopy_id] = canopy2\n",
    "    return canopies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(vector1, vector2):\n",
    "        #print(vector1)\n",
    "        #print(vector2)\n",
    "        return np.sqrt(np.sum(np.power(vector1-vector2, 2)))\n",
    "\n",
    "def getDistance(row_center, row_sample):\n",
    "        #print(row_center)\n",
    "        row_center = np.asarray(row_center)\n",
    "        #row_center = np.asarray(row_sample)\n",
    "        return euclideanDistance(row_center, row_sample)\n",
    "\n",
    "def getSquaredError(data, kmeans):\n",
    "    distances = []\n",
    "    for i in range(k): # Qtd de clusters\n",
    "        distance = 0\n",
    "        for index_labels, value_labels in enumerate(kmeans.labels_): #kmeans.labels_ possui o cluster de cada elemento\n",
    "            if (i == value_labels):\n",
    "                #print(value_labels)\n",
    "                distance = distance + getDistance(kmeans.cluster_centers_[value_labels], data.loc[index_labels].values)\n",
    "        distances.append(distance) #Erro quadratico medio de cada cluster\n",
    "    distances = np.asarray(distances)\n",
    "    error = np.sum(distances)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Density Canopy -------------- #\n",
    "\n",
    "# Definition 1\n",
    "#OBS.: enumerate com numpy mto mais rápido que iterrows\n",
    "def mean_dist(D):\n",
    "    n = D.shape[0]\n",
    "    D = D.values\n",
    "    sum_D = np.zeros((n, n))\n",
    "    for i, row_i in enumerate(D):\n",
    "        for j, row_j in enumerate(D[i+1:,]):\n",
    "            sum_D[i][j] = euclideanDistance(row_i, row_j)\n",
    "    return (2/(n*(n-1))) * np.sum(sum_D)\n",
    "\n",
    "# Definition 2\n",
    "def get_densities(D, meanDis):\n",
    "    densities = np.zeros(D.shape[0], dtype=int)\n",
    "    aux_D = D.values\n",
    "    for i, row_i in enumerate(aux_D):\n",
    "        for j, row_j in enumerate(aux_D):\n",
    "            if euclideanDistance(row_i, row_j) - meanDis < 0:\n",
    "                densities[i] += 1\n",
    "    df = pd.DataFrame(data=densities, columns=[\"density\"])\n",
    "    return df\n",
    "\n",
    "#Definition 3\n",
    "def cluser_dist_mean(D, densities, meanDis):\n",
    "    a = np.zeros(D.shape[0])\n",
    "    densities_aux = densities.copy().values\n",
    "    for i, row_i in enumerate(D.values):\n",
    "        sum_dists = 0\n",
    "        for j, row_j in enumerate(D.values):\n",
    "            dist = euclideanDistance(row_i, row_j)\n",
    "            if dist - meanDis < 0:\n",
    "                sum_dists += dist\n",
    "        a[i] = (2/(densities_aux[i]*(densities_aux[i]-1))) * sum_dists\n",
    "    return a\n",
    "\n",
    "#Definition 4\n",
    "def clusters_dist(D, densities):\n",
    "    s = []\n",
    "    densities_aux = densities.values\n",
    "    for i, row_i in enumerate(D.values):\n",
    "        maxDist = 0\n",
    "        minDist = float(\"inf\")\n",
    "        dist = 0\n",
    "        flag = 1 #Se flag=0 entao min dist, se flag=1 retornar max dist\n",
    "        for j, row_j in enumerate(D.values):\n",
    "            dist = euclideanDistance(row_i, row_j)\n",
    "            if densities_aux[j] > densities_aux[i]:\n",
    "                flag = 0\n",
    "                if (dist < minDist):\n",
    "                    minDist = dist\n",
    "            else:\n",
    "                if (dist > maxDist):\n",
    "                    maxDist = dist\n",
    "#             if densities[j] == np.amax(densities):\n",
    "#                 flag = 1\n",
    "        if flag == 1:\n",
    "            s.append(maxDist)\n",
    "        else: # p(j) > p(i)\n",
    "            s.append(minDist)\n",
    "    return s\n",
    "\n",
    "# Definition 6\n",
    "def product_weight(p, a, s):\n",
    "    w = []\n",
    "    for i, row_i in enumerate(p):\n",
    "        w.append(p[i] * (1/a[i]) * s[i])\n",
    "    return w\n",
    "        \n",
    "def getCluster(D, meanDis, firstExecution=True, index=None): \n",
    "    aux_D = D.copy()\n",
    "    df = get_densities(D, meanDis)\n",
    "    if (firstExecution == True): #Primeira execução pega o de maior densidade\n",
    "        rows = D.iloc[df.idxmax(axis=0)].values\n",
    "        row_i = rows[-1] #pegando o último index com maior peso, caso tenha mais de 1\n",
    "    else:\n",
    "        row_i = D.iloc[index].values #pegando index passado, no caso o com maior peso\n",
    "    cluster = []\n",
    "    for j, row_j in enumerate(aux_D.values):\n",
    "        if euclideanDistance(row_i, row_j) - meanDis < 0:\n",
    "            cluster.append(j)\n",
    "    #print (cluster)\n",
    "    #auxD.drop(cluster, inplace=True)\n",
    "    #display(auxD)\n",
    "    return row_i, cluster #Elemento central e cluster\n",
    "\n",
    "def removeOutliers(aux_D, densities, s, meanDis):\n",
    "    #remove elemento com densidade = 1 e que o s[i] seja maior que o raio\n",
    "    outliers = []\n",
    "    for i, row_i in enumerate(aux_D.values):\n",
    "        if densities[i] == 1 and s[i] > meanDis:\n",
    "            outliers.append(i)\n",
    "    aux_D.drop(outliers, inplace=True) #removendo outliers\n",
    "    aux_D.reset_index(drop=True, inplace=True)\n",
    "    densities = np.delete(densities, outliers, 0)\n",
    "    s = np.delete(s, outliers, 0)\n",
    "    return aux_D, densities, s\n",
    "\n",
    "def run(D):\n",
    "    meanDis = mean_dist(D)\n",
    "    centers, cluster = getCenter(D, meanDis)\n",
    "    centers = np.array([centers])\n",
    "    aux_D = D.copy()\n",
    "    aux_D.drop(cluster, inplace=True) #removendo cluster ja identificado\n",
    "    aux_D.reset_index(drop=True, inplace=True)\n",
    "    while (not aux_D.empty):\n",
    "        new_densities = get_densities(aux_D, meanDis)\n",
    "        a = cluser_dist_mean(aux_D, new_densities, meanDis) #mantem-se meanDis\n",
    "        s = clusters_dist(aux_D, new_densities)\n",
    "        densities = new_densities.values\n",
    "        aux_D, densities, s = removeOutliers(aux_D, densities, s, meanDis)\n",
    "        aux_index = np.argmax(product_weight(densities, a, s))\n",
    "#         for i, row_i in enumerate(aux_D.values):\n",
    "#             if (densities[i] * (1/a[i]) * s[i]) > weight:\n",
    "#                 weight = densities[i] * (1/a[i]) * s[i]\n",
    "#                 print(\"densidade: \", densities[i], \"a: \", a[i], \"s: \", s[i], \"weight: \", weight)\n",
    "#                 aux_index = i\n",
    "        aux_center, cluster = getCenter(aux_D, meanDis, firstExecution=False, index=aux_index)\n",
    "        aux_center = np.array([aux_center])\n",
    "        centers = np.concatenate((centers, aux_center), axis=0)\n",
    "        aux_D.drop(cluster, inplace=True) #removendo cluster ja identificado\n",
    "        aux_D.reset_index(drop=True, inplace=True)\n",
    "    print(\"KS:\", len(centers), centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### possiveis problemas que podem estar ocorrendo \n",
    "1. em getAs a função estar errada\n",
    "2. Checar se os valores dropados estão corretos\n",
    "3. Ver se foi retirado o index tb\n",
    "4. Checar se esses limites de outliers são suficientes\n",
    "5. Checar se algum índice não está estranho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"soybean-small\", \"iris\", \"wine\",  \"segmentation\", \"ionosphere\"]\n",
    "ks = [4,3,3,7,2]\n",
    "#kmeansTypes = [\"random\", \"k-means++\"]\n",
    "kmeansTypes = [\"random\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- random test ---------\n",
      "\n",
      "----- soybean-small -----\n",
      "\n",
      "(47, 36)\n",
      "KS: 3 [[3 1 2 0 0 2 1 2 1 1 1 1 0 2 2 0 0 0 1 0 2 2 0 0 0 0 0 3 4 0 0 0 0 0 1]\n",
      " [4 0 0 1 0 2 3 1 1 1 1 1 0 2 2 0 0 0 1 0 0 3 0 0 0 2 1 0 4 0 0 0 0 0 0]\n",
      " [5 0 2 1 0 3 1 1 1 2 1 1 0 2 2 0 0 0 1 1 3 0 1 1 0 0 0 0 4 0 0 0 0 0 0]]\n",
      "\n",
      "----- iris -----\n",
      "\n",
      "(150, 5)\n",
      "KS: 3 [[5.6 2.9 3.6 1.3]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [6.9 3.2 5.7 2.3]]\n",
      "\n",
      "----- wine -----\n",
      "\n",
      "(178, 14)\n",
      "KS: 4 [[2.000e+00 1.196e+01 1.090e+00 2.300e+00 2.100e+01 1.010e+02 3.380e+00\n",
      "  2.140e+00 1.300e-01 1.650e+00 3.210e+00 9.900e-01 3.130e+00]\n",
      " [1.000e+00 1.376e+01 1.530e+00 2.700e+00 1.950e+01 1.320e+02 2.950e+00\n",
      "  2.740e+00 5.000e-01 1.350e+00 5.400e+00 1.250e+00 3.000e+00]\n",
      " [2.000e+00 1.225e+01 1.730e+00 2.120e+00 1.900e+01 8.000e+01 1.650e+00\n",
      "  2.030e+00 3.700e-01 1.630e+00 3.400e+00 1.000e+00 3.170e+00]\n",
      " [2.000e+00 1.221e+01 1.190e+00 1.750e+00 1.680e+01 1.510e+02 1.850e+00\n",
      "  1.280e+00 1.400e-01 2.500e+00 2.850e+00 1.280e+00 3.070e+00]]\n",
      "\n",
      "----- segmentation -----\n",
      "\n",
      "(210, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS: 4 [[ 1.4000000e+02  7.3000000e+01  9.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  1.7222214e+00  8.2775980e-01  7.7777740e-01\n",
      "   1.0036957e+00  4.6296295e+01  4.5666668e+01  5.1111110e+01\n",
      "   4.2111110e+01 -1.8888888e+00  1.4444445e+01 -1.2555555e+01\n",
      "   5.1111110e+01  1.7615560e-01 -1.6815889e+00]\n",
      " [ 4.0000000e+00  1.8900000e+02  9.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  2.0555565e+00  3.8851852e+00  1.1722221e+01\n",
      "   1.1459634e+02  2.6444445e+01  2.3444445e+01  3.3000000e+01\n",
      "   2.2888890e+01 -9.0000000e+00  1.9666666e+01 -1.0666667e+01\n",
      "   3.3000000e+01  2.7147257e-01 -2.1010017e+00]\n",
      " [ 1.2400000e+02  2.9000000e+01  9.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  1.0000013e+00  7.1110760e-01  1.0555534e+00\n",
      "   9.0741664e-01  1.2844444e+02  1.1922222e+02  1.4288889e+02\n",
      "   1.2322222e+02 -2.7666666e+01  4.3333332e+01 -1.5666667e+01\n",
      "   1.4288889e+02  1.6561614e-01 -2.2711280e+00]\n",
      " [ 1.9700000e+02  2.3600000e+02  9.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  2.4444444e+00  6.8296280e+00  3.3333333e+00\n",
      "   7.5999980e+00  1.6074074e+01  1.3111111e+01  1.6666668e+01\n",
      "   1.8444445e+01 -8.8888890e+00  1.7777778e+00  7.1111110e+00\n",
      "   1.8555555e+01  2.9272884e-01  2.7898002e+00]]\n",
      "\n",
      "----- ionosphere -----\n",
      "\n",
      "(351, 35)\n",
      "KS: 7 [[ 1.       0.       0.21429 -0.09524  0.33333  0.07143  0.19048  0.19048\n",
      "   0.2381   0.09524  0.40476  0.02381  0.30952 -0.04762  0.30952 -0.04762\n",
      "   0.28571 -0.11905  0.33333  0.04762  0.30952  0.       0.21429 -0.11905\n",
      "   0.35714 -0.04762  0.22109 -0.0229   0.19048  0.       0.16997 -0.02034\n",
      "   0.14694 -0.01877]\n",
      " [ 1.       0.       1.      -0.5421   1.      -1.       1.      -1.\n",
      "   1.       0.36217  1.      -0.41119  1.       1.       1.      -1.\n",
      "   1.      -0.29354  1.      -0.93599  1.       1.       1.       1.\n",
      "   1.      -0.40888  1.      -0.62745  1.      -1.       1.      -1.\n",
      "   1.      -1.     ]\n",
      " [ 1.       0.       0.9287   0.33164  0.76168  0.62349  0.49305  0.84266\n",
      "   0.21592  0.95193 -0.13956  0.96167 -0.47202  0.8359  -0.70747  0.6549\n",
      "  -0.87474  0.3675  -0.91814  0.05595 -0.89824 -0.26173 -0.73969 -0.54069\n",
      "  -0.50757 -0.74735 -0.22323 -0.86122  0.0781  -0.87159  0.36021 -0.78057\n",
      "   0.59407 -0.6027 ]\n",
      " [ 1.       0.       1.       0.06843  1.       0.14211  1.       0.22108\n",
      "   1.      -0.125    1.       0.39495  1.       0.48981  1.       0.58986\n",
      "  -0.375    1.       1.       0.       1.       0.92001  1.       1.\n",
      "   1.       1.       1.       1.       1.       0.25     1.       1.\n",
      "   1.       1.     ]\n",
      " [ 0.       0.       1.      -1.       1.      -1.       1.      -1.\n",
      "   1.      -1.       1.       1.       1.       1.       1.      -1.\n",
      "   1.       1.       1.       1.       1.       1.       1.      -1.\n",
      "   1.      -1.       1.      -1.       1.       0.65625  0.       0.\n",
      "   1.      -1.     ]\n",
      " [ 1.       0.       1.       0.54902  0.62745  1.       0.01961  1.\n",
      "  -0.4902   0.92157 -0.82353  0.58824 -1.       0.11765 -0.96078 -0.33333\n",
      "  -0.64706 -0.68627 -0.23529 -0.86275  0.35294 -1.       0.7451  -0.72549\n",
      "   0.92157 -0.21569  0.92874  0.21876  0.72549  0.56863  0.23529  0.90196\n",
      "  -0.11765  0.90196]\n",
      " [ 1.       0.       0.94531 -0.03516 -1.      -0.33203 -1.      -0.01563\n",
      "   0.97266  0.01172  0.93359 -0.01953 -1.       0.16406 -1.      -0.00391\n",
      "   0.95313 -0.03516  0.92188 -0.02734 -0.99219  0.11719 -0.93359  0.34766\n",
      "   0.95703 -0.00391  0.82041  0.13758  0.90234 -0.06641 -1.      -0.1875\n",
      "  -1.      -0.34375]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "for kmeansType in kmeansTypes:\n",
    "    print (\"--------- \"+ kmeansType +\" test ---------\")\n",
    "    for index, file in enumerate(files):\n",
    "        print (\"\\n----- \"+file+\" -----\\n\")\n",
    "        data = pd.read_csv(\"datasets/\"+file+\".data\", header=None)\n",
    "        print (data.shape)\n",
    "        if file == \"segmentation\": #Target eh na primeira coluna\n",
    "            target = data.iloc[:,0]\n",
    "            data = data.iloc[:,1:]   \n",
    "        else: #Target na última coluna\n",
    "            target = data.iloc[:,-1]\n",
    "            data = data.iloc[:,:-1]\n",
    "        run(data)\n",
    "        clustering_times = []\n",
    "        start = time()\n",
    "        k = ks[index]\n",
    "        kmeans = KMeans(n_clusters=k, random_state=100, init=kmeansType, n_init=1, max_iter=100).fit(data)\n",
    "        #display(data)\n",
    "        error = getSquaredError(data, kmeans)\n",
    "        #print(kmeans.labels_)\n",
    "        end = time()\n",
    "        T1 = error/(data.shape[0])\n",
    "        T2 = error/(data.shape[0]/2)\n",
    "        \n",
    "        #print(canopy(data.values, T1, T2))\n",
    "        #print(\"Erro quadrático médio: \",error)\n",
    "        clustering_times.append(end - start)\n",
    "        #print(clustering_times)\n",
    "        #print(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usando numpy em vez do pandas pode tornar mais rápido pra essas operações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
